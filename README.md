# LIVE DEPLOYMENT NOT POSSIBLE ON RENDER DUE TO BIG MODEL SIZE CAUSING GIT TO CHOKE ON PUSHES. LIVE DOWNLOAD LINK ON itch.io NOT AVAILABLE EITHER DUE TO HUGE SIZE OF MODEL.


DOWNLOAD THE EXECUTEABLE .exe FILE FROM DRIVE (https://drive.google.com/drive/folders/1uQYrXVQ6V-DJXEkGeUqBnXd-AaHEbwOa?usp=drive_link).
FROM file.kiwi (https://file.kiwi/d11ef2e1#EaDDD0zIu0L6KLetXWB9lw)

# ğŸ“° Fake News Detection System

An end-to-end **Fake News Detection** web application that analyzes online news articles using **Natural Language Processing**, **BERT-based content classification**, and **publisher credibility scoring** to estimate the likelihood of misinformation.

Built as a modular, explainable, and privacy-conscious system, this project combines ML inference with transparent scoring logic and a clean web UI.

<img src="images/icon.ico" height="400" width="200">

---

## âœ¨ Key Features

* ğŸ” **Content Analysis with BERT**
  Classifies articles into **Neutral**, **Biased**, or **Contradictory** using a fine-tuned transformer model.

* ğŸ›ï¸ **Publisher Credibility Scoring**
  Looks up known publishers from a curated Supabase database (score range: 0â€“10).

* ğŸ§® **Explainable Final Verdict**
  Combines content score + publisher score into a transparent, threshold-based credibility verdict.

* ğŸŒ **Flexible Input**
  Analyze either:

<img src="images/output1.png" height="700" width="850">

* ğŸ” **Privacy First**
  No article text or user data is stored. All inference happens in-memory.

---

## ğŸ§  How the System Works

<img src="images/DFD.png" height="2000" width="4000">

1. **User Input**
   User submits a news article as a link or raw text.

2. **Article Extraction**

   * URLs are scraped using **Firecrawl** (with BeautifulSoup fallback).
   * Raw text is passed directly.

3. **BERT Classification**
   The article is classified into one of three categories:

   * Neutral
   * Biased
   * Contradictory

4. **Scoring Logic**

   **Category Score**

   * Neutral â†’ 10
   * Biased â†’ 5
   * Contradictory â†’ 0

   **Publisher Score**

   * Retrieved from Supabase (0â€“10)
   * Defaults to 0 if unknown

5. **Final Verdict**

   ```text
   Total Score = Category Score + Publisher Score

   â‰¥ 15  â†’ Possible high credibility
   7â€“14  â†’ Needs further verification
   < 7   â†’ Credibility uncertain
   ```

---

## ğŸ–¥ï¸ Web Interface

### Home Page

<img src="images/UI 1.png" height="2000" width="4000">

Users can choose whether to submit a **link** or **article text**.

### Submit Article Link

<img src="images/ui2.png" height="2000" width="4000">

* Automatically extracts article content
* Optional publisher input

### Submit Article Text

<img src="images/ui3.png" height="2000" width="4000">

* Paste full article content directly
* Optional publisher input

---

## ğŸ“Š Example Output

### Credibility Result Page

<img src="images/output 2.png" height="2000" width="4000">

Displays:

* Final credibility score
* Verdict explanation
* Content category
* Publisher credibility

## ğŸ¤– Model Training

The project includes a full **BERT training pipeline** using HuggingFace Transformers.

* Model: `bert-base-uncased`
* Labels: Neutral, Biased, Contradictory
* Frameworks: PyTorch + HuggingFace Trainer

### Training Progress

<img src="images/during training.png" height="1000" width="3000">

### Evaluation Results

<img src="images/eval test.png" height="500" width="2000">

Achieves high accuracy on the test set, demonstrating strong contextual understanding.

---

## ğŸ—‚ï¸ Project Structure

```text
fake_news_detector/
â”‚
â”œâ”€â”€ app.py                  # Flask app entry point
â”œâ”€â”€ config.py               # Environment & config loading
â”œâ”€â”€ requirements.txt
â”‚
â”œâ”€â”€ scraping/               # Article extraction
â”‚   â”œâ”€â”€ article_reader.py
â”‚   â””â”€â”€ scraper.py
â”‚
â”œâ”€â”€ model/                  # NLP models
â”‚   â”œâ”€â”€ bert_classifier.py
â”‚   â””â”€â”€ train_bert.py
â”‚
â”œâ”€â”€ scoring/                # Scoring logic
â”‚   â”œâ”€â”€ category_score.py
â”‚   â”œâ”€â”€ publisher_score.py
â”‚   â””â”€â”€ verdict.py
â”‚
â”œâ”€â”€ database/               # Supabase integration
â”‚   â”œâ”€â”€ supabase_client.py
â”‚   â””â”€â”€ schema.sql
â”‚
â”œâ”€â”€ utils/                  # Helpers
â”‚   â”œâ”€â”€ text_cleaner.py
â”‚   â””â”€â”€ publisher_normalizer.py
â”‚
â”œâ”€â”€ data/                   # Training datasets
â”‚   â”œâ”€â”€ train.csv
â”‚   â”œâ”€â”€ val.csv
â”‚   â””â”€â”€ test.csv
â”‚
â”œâ”€â”€ templates/              # HTML UI
â”‚   â”œâ”€â”€ index.html
â”‚   â”œâ”€â”€ article_link.html
â”‚   â””â”€â”€ article_text.html
â”‚
â””â”€â”€ .env
```

---

## âš™ï¸ Tech Stack

* **Backend**: Python 3.10, Flask
* **NLP / ML**: BERT, HuggingFace Transformers, PyTorch
* **Scraping**: Firecrawl, Requests, BeautifulSoup
* **Database**: Supabase (PostgreSQL)
* **Frontend**: HTML, CSS (Flask templates)

---

## ğŸš€ Running the Project

```bash
pip install -r requirements.txt
python app.py
```

Make sure your `.env` file contains:

```env
FIRECRAWL_API_KEY=your_key
SUPABASE_URL=your_url
SUPABASE_KEY=your_key
```

---

## âš ï¸ Disclaimer

This system provides an **automated credibility estimate** and is intended as a **decision-support tool**, not a definitive judgment of truth.

---

## ğŸ‘¨â€ğŸ’» Author

Built as part of an AI/ML-focused project exploring **misinformation detection**, **explainable scoring**, and **responsible NLP deployment**.

If this helped you, feel free to â­ the repository and experiment further.

